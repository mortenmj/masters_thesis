% Chapter Template
\providecommand{\rootfolder}{../..} % Relative path to main.tex
\documentclass[\rootfolder/main.tex]{subfiles}
\begin{document}

\chapter{Results}
\label{ch:results} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ch:foo}

% TODO: Results intro

%----------------------------------------------------------------------------------------
%	SECTION BEHAVIOR TREE CONTROL SYSTEM
%----------------------------------------------------------------------------------------

\section{Behavior tree control system}

% TODO: Finish control system results

The behavior tree solution implemented using behavior3, as described in \cref{ch:implementation-control} was found to be scalable and easy to use.
In particular, the ability to create behavior trees using configuration files and load them using \acrshort{ros} launch files was found to be a significant advantage.
The graphical editor behavior3editor simplified behavior tree creation further.
Compared to the more manual approaches required with the other libraries that were evaluated, where the behavior tree is specified in code, this was found to greatly simplify the design process.

It was found that behavior trees are well suited for splitting behavior into their smallest components, and composing more complex behaviors from sub-trees of these units.
However, it was also found that composing complex control systems from basic blocks can lead to behavior which can be hard to understand without the ability to visualize the flow of control in the system.

%----------------------------------------------------------------------------------------
%	SECTION CONTROL SYSTEM MONITORING APPLICATION
%----------------------------------------------------------------------------------------

\section{Control system monitoring application}

% TODO: Finish monitoring application results

The visualization software, described in \cref{ch:implementation-monitoring}, has been a valuable diagnostic tool.
The software performs well, and as part of the rqt framework it can be used in the same graphical interface as other useful plugins that exist for rqt.
In the course of developing behavior trees for testing the control system, it was found that being able to visualize the control flow of the system greatly aided in the design process.
On some occasions the behavior of the system was difficult to understand initially, but once visualized was simple to debug.
It is believed will be useful to the project when increasingly complex behavior is implemented.

%----------------------------------------------------------------------------------------
%	SECTION OBJECT DETECTION VISUALIZATION
%----------------------------------------------------------------------------------------

\section{Object detection visualization}

Here, the object detection system described in \cref{ch:implementation-objdet} is evaluated.
Two parts of the image processing pipeline are considered, being the image transmission from the zed\_ros\_wrapper to the object\_detection, running as \CC nodes and nodelets, and as Python nodes, as described in \cref{ch:implementation-objdet}.
In comparing the execution times of the different implementations, some interesting results are found.

Firstly, the difference when running the \CC implementation in the nodelet configuration compared to the node configuration, that is when using shared memory rather than TCP for data transfer, is found to be small.
While the difference is almost 20\%, this amounts to a difference of only 2.5 milliseconds.
Furthermore, the image transmission step is largely insignificant compared to the time it takes to process the image by running it through the neural network.
Even for the Python implementation, transmission time increases by only 30\% compared to the nodelet implementation in \CC, and accounts for about 1\% of the total processing time.

\begin{table}[h]
    \centering
    \begin{tabular}{lrrr} \toprule
        \textbf{Task}               & \CC (nodes) & \CC (nodelets) & Python  \\ \midrule
        \textbf{Image transmission} & 13.24       & 15.75          & 17.08   \\
        \textbf{Object detection}   & 2147.48     & 2147.48        & 1524.02 \\ \bottomrule
    \end{tabular}
    \caption{Execution times of object detection implementations, in milliseconds.}
\end{table}

Secondly, as expected, the object detection takes the same amount of time for both \CC implementations.
However, unexpectedly, the Python implementation takes a shorter amount of time clocking in at only 70\% of the runtime of the \CC implementations.
This difference was confirmed not to be due to any differences in the pre- or post-processing done to the results, but rather be due to differences in OpenCV itself.
Similar results have also been confirmed by others \cite{Liu}.
It should be noted that these results are from running the neural network on a \acrshort{cpu}, and that improved performanced for the object detection phase should be expected when running on a \acrfull{gpu}.
While OpenCV supports OpenCL as a backend for the DNN module, this is only available on Intel \acrshort{gpu}s, while the Cyborg project uses an Nvidia \acrshort{gpu} for image processing.
Support for a CUDA backend for the DNN module is under active development, it is expected that this will greatly improve performance with minimal changes required to our software.

Other parts of the image processing, such as calculating the average depth of the object within the image, are performed using the same underlying libraries in both \CC and Python and as such acheive nearly identical performance.

\end{document}
